{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oil Spill Detection - Data Preprocessing\n",
    "\n",
    "This notebook implements the complete data preprocessing pipeline for the oil spill detection project.\n",
    "\n",
    "## Objectives\n",
    "1. Apply preprocessing techniques to satellite imagery\n",
    "2. Implement noise reduction for SAR images\n",
    "3. Normalize pixel values and enhance contrast\n",
    "4. Create processed dataset ready for training\n",
    "5. Generate comprehensive preprocessing statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom modules\n",
    "from data.data_loader import OilSpillDataLoader\n",
    "from data.preprocessor import OilSpillPreprocessor, create_preprocessing_report\n",
    "from data.augmentation import OilSpillAugmentor\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset and Initialize Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_dir = \"../data/raw\"\n",
    "loader = OilSpillDataLoader(data_dir)\n",
    "dataset_info = loader.load_dataset_info()\n",
    "\n",
    "print(f\"Dataset loaded: {dataset_info['total_samples']} samples\")\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = OilSpillPreprocessor(target_size=(256, 256))\n",
    "\n",
    "print(\"Preprocessor initialized with target size: (256, 256)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Technique Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample image for preprocessing comparison\n",
    "sample_image, sample_mask = loader.load_image_pair(0)\n",
    "\n",
    "print(f\"Sample image shape: {sample_image.shape}\")\n",
    "print(f\"Sample mask shape: {sample_mask.shape}\")\n",
    "print(f\"Image value range: [{sample_image.min():.3f}, {sample_image.max():.3f}]\")\n",
    "print(f\"Mask value range: [{sample_mask.min():.3f}, {sample_mask.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different normalization methods\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(sample_image)\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Different normalization methods\n",
    "norm_methods = ['minmax', 'zscore', 'robust']\n",
    "for i, method in enumerate(norm_methods):\n",
    "    normalized = preprocessor.normalize_image(sample_image, method=method)\n",
    "    axes[0, i+1].imshow(normalized)\n",
    "    axes[0, i+1].set_title(f'{method.title()} Normalization')\n",
    "    axes[0, i+1].axis('off')\n",
    "\n",
    "# Histogram comparison\n",
    "axes[1, 0].hist(sample_image.flatten(), bins=50, alpha=0.7, label='Original')\n",
    "axes[1, 0].set_title('Original Histogram')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "for i, method in enumerate(norm_methods):\n",
    "    normalized = preprocessor.normalize_image(sample_image, method=method)\n",
    "    axes[1, i+1].hist(normalized.flatten(), bins=50, alpha=0.7, label=method)\n",
    "    axes[1, i+1].set_title(f'{method.title()} Histogram')\n",
    "    axes[1, i+1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Noise Reduction Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different noise reduction methods\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(sample_image)\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Different noise reduction methods\n",
    "filter_methods = ['gaussian', 'median', 'bilateral']\n",
    "for i, method in enumerate(filter_methods):\n",
    "    filtered = preprocessor.reduce_speckle_noise(sample_image, filter_type=method)\n",
    "    axes[0, i+1].imshow(filtered)\n",
    "    axes[0, i+1].set_title(f'{method.title()} Filter')\n",
    "    axes[0, i+1].axis('off')\n",
    "\n",
    "# Show difference maps\n",
    "axes[1, 0].imshow(np.zeros_like(sample_image[:,:,0]), cmap='gray')\n",
    "axes[1, 0].set_title('Reference')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "for i, method in enumerate(filter_methods):\n",
    "    filtered = preprocessor.reduce_speckle_noise(sample_image, filter_type=method)\n",
    "    diff = np.abs(sample_image - filtered)\n",
    "    axes[1, i+1].imshow(np.mean(diff, axis=2), cmap='hot')\n",
    "    axes[1, i+1].set_title(f'{method.title()} Difference')\n",
    "    axes[1, i+1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Contrast Enhancement Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare contrast enhancement methods\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(sample_image)\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# CLAHE enhancement\n",
    "clahe_enhanced = preprocessor.enhance_contrast(sample_image, method='clahe')\n",
    "axes[0, 1].imshow(clahe_enhanced)\n",
    "axes[0, 1].set_title('CLAHE Enhanced')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Histogram equalization\n",
    "hist_enhanced = preprocessor.enhance_contrast(sample_image, method='histogram_eq')\n",
    "axes[0, 2].imshow(hist_enhanced)\n",
    "axes[0, 2].set_title('Histogram Equalized')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Histograms\n",
    "axes[1, 0].hist(sample_image.flatten(), bins=50, alpha=0.7, label='Original')\n",
    "axes[1, 0].set_title('Original Histogram')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].hist(clahe_enhanced.flatten(), bins=50, alpha=0.7, label='CLAHE', color='orange')\n",
    "axes[1, 1].set_title('CLAHE Histogram')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "axes[1, 2].hist(hist_enhanced.flatten(), bins=50, alpha=0.7, label='Hist Eq', color='green')\n",
    "axes[1, 2].set_title('Hist Eq Histogram')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Complete Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate complete preprocessing pipeline\n",
    "preprocessor.visualize_preprocessing_effects(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process Complete Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive preprocessing statistics\n",
    "print(\"Calculating preprocessing statistics for the entire dataset...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "stats = preprocessor.calculate_dataset_statistics(\n",
    "    loader.image_paths, \n",
    "    loader.mask_paths\n",
    ")\n",
    "\n",
    "print(\"\\nPreprocessing Statistics:\")\n",
    "print(json.dumps(stats, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for processed data\n",
    "processed_dir = \"../data/processed\"\n",
    "processed_images_dir = os.path.join(processed_dir, \"images\")\n",
    "processed_masks_dir = os.path.join(processed_dir, \"masks\")\n",
    "\n",
    "os.makedirs(processed_images_dir, exist_ok=True)\n",
    "os.makedirs(processed_masks_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Processing and saving {len(loader.image_paths)} image pairs...\")\n",
    "\n",
    "# Process and save all images\n",
    "processed_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "for i, (img_path, mask_path) in enumerate(tqdm(\n",
    "    zip(loader.image_paths, loader.mask_paths),\n",
    "    total=len(loader.image_paths),\n",
    "    desc=\"Processing images\"\n",
    ")):\n",
    "    try:\n",
    "        # Load original image and mask\n",
    "        image = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if image is None or mask is None:\n",
    "            failed_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        mask = mask.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        processed_image = preprocessor.preprocess_image(\n",
    "            image,\n",
    "            apply_noise_reduction=True,\n",
    "            apply_contrast_enhancement=True,\n",
    "            normalization_method='minmax'\n",
    "        )\n",
    "        \n",
    "        processed_mask = preprocessor.preprocess_mask(mask, threshold=0.5)\n",
    "        \n",
    "        # Convert back to uint8 for saving\n",
    "        processed_image_uint8 = (processed_image * 255).astype(np.uint8)\n",
    "        processed_mask_uint8 = (processed_mask * 255).astype(np.uint8)\n",
    "        \n",
    "        # Save processed files\n",
    "        base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        \n",
    "        processed_img_path = os.path.join(processed_images_dir, f\"{base_name}.png\")\n",
    "        processed_mask_path = os.path.join(processed_masks_dir, f\"{base_name}.png\")\n",
    "        \n",
    "        cv2.imwrite(processed_img_path, cv2.cvtColor(processed_image_uint8, cv2.COLOR_RGB2BGR))\n",
    "        cv2.imwrite(processed_mask_path, processed_mask_uint8)\n",
    "        \n",
    "        processed_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "        failed_count += 1\n",
    "        continue\n",
    "\n",
    "print(f\"\\nProcessing complete!\")\n",
    "print(f\"Successfully processed: {processed_count} images\")\n",
    "print(f\"Failed to process: {failed_count} images\")\n",
    "print(f\"Success rate: {(processed_count/(processed_count+failed_count))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Augmentation Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize augmentor and show augmentation examples\n",
    "augmentor = OilSpillAugmentor(target_size=(256, 256))\n",
    "\n",
    "# Load a sample for augmentation demonstration\n",
    "sample_image, sample_mask = loader.load_image_pair(0)\n",
    "\n",
    "# Show augmentation examples\n",
    "augmentor.visualize_augmentations(\n",
    "    sample_image,\n",
    "    sample_mask,\n",
    "    num_examples=5,\n",
    "    transform_type='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Small Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small augmented dataset for demonstration\n",
    "augmented_dir = \"../data/augmented_sample\"\n",
    "\n",
    "# Use first 10 images for augmentation demo\n",
    "sample_images = loader.image_paths[:10]\n",
    "sample_masks = loader.mask_paths[:10]\n",
    "\n",
    "print(f\"Creating augmented dataset with {len(sample_images)} base images...\")\n",
    "\n",
    "aug_stats = augmentor.create_augmented_dataset(\n",
    "    sample_images,\n",
    "    sample_masks,\n",
    "    augmented_dir,\n",
    "    augmentations_per_image=3,\n",
    "    transform_type='train'\n",
    ")\n",
    "\n",
    "print(\"\\nAugmentation Statistics:\")\n",
    "for key, value in aug_stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Preprocessing Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs processed images\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "# Load and compare multiple samples\n",
    "for i in range(4):\n",
    "    try:\n",
    "        # Load original\n",
    "        original_image, original_mask = loader.load_image_pair(i)\n",
    "        \n",
    "        # Process\n",
    "        processed_image = preprocessor.preprocess_image(original_image)\n",
    "        processed_mask = preprocessor.preprocess_mask(original_mask)\n",
    "        \n",
    "        # Show original\n",
    "        axes[0, i].imshow(original_image)\n",
    "        axes[0, i].set_title(f'Original {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Show processed\n",
    "        axes[1, i].imshow(processed_image)\n",
    "        axes[1, i].set_title(f'Processed {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Show mask comparison\n",
    "        mask_comparison = np.hstack([original_mask, processed_mask])\n",
    "        axes[2, i].imshow(mask_comparison, cmap='gray')\n",
    "        axes[2, i].set_title(f'Masks {i+1} (Orig|Proc)')\n",
    "        axes[2, i].axis('off')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing sample {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results and Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directories\n",
    "os.makedirs('../results/figures', exist_ok=True)\n",
    "os.makedirs('../results/data', exist_ok=True)\n",
    "\n",
    "# Save preprocessing statistics\n",
    "preprocessor.save_preprocessing_stats('../results/data/preprocessing_stats.json')\n",
    "\n",
    "# Save augmentation statistics\n",
    "augmentor.save_augmentation_stats('../results/data/augmentation_stats.json')\n",
    "\n",
    "# Create comprehensive preprocessing report\n",
    "create_preprocessing_report(stats, '../results/figures')\n",
    "\n",
    "print(\"All results saved to ../results/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Final Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary\n",
    "print(\"=\" * 70)\n",
    "print(\"PREPROCESSING PIPELINE SUMMARY REPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä PROCESSING RESULTS:\")\n",
    "print(f\"   ‚Ä¢ Original dataset: {dataset_info['total_samples']} samples\")\n",
    "print(f\"   ‚Ä¢ Successfully processed: {processed_count} samples\")\n",
    "print(f\"   ‚Ä¢ Processing success rate: {(processed_count/(processed_count+failed_count))*100:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Augmented samples created: {aug_stats['generated_augmentations']}\")\n",
    "\n",
    "print(f\"\\nüîß PREPROCESSING PIPELINE:\")\n",
    "print(f\"   ‚Ä¢ Target image size: 256x256 pixels\")\n",
    "print(f\"   ‚Ä¢ Noise reduction: Gaussian filtering\")\n",
    "print(f\"   ‚Ä¢ Contrast enhancement: CLAHE\")\n",
    "print(f\"   ‚Ä¢ Normalization: Min-Max scaling\")\n",
    "print(f\"   ‚Ä¢ Mask binarization: Threshold = 0.5\")\n",
    "\n",
    "print(f\"\\nüìà DATASET STATISTICS:\")\n",
    "if stats:\n",
    "    print(f\"   ‚Ä¢ Mean pixel value: {stats['pixel_statistics']['mean']:.3f}\")\n",
    "    print(f\"   ‚Ä¢ Pixel std deviation: {stats['pixel_statistics']['std']:.3f}\")\n",
    "    print(f\"   ‚Ä¢ Average spill ratio: {stats['spill_statistics']['mean_spill_ratio']:.3f}\")\n",
    "    print(f\"   ‚Ä¢ Samples with spills: {stats['spill_statistics']['samples_with_spill']}\")\n",
    "\n",
    "print(f\"\\nüìÅ OUTPUT DIRECTORIES:\")\n",
    "print(f\"   ‚Ä¢ Processed images: ../data/processed/\")\n",
    "print(f\"   ‚Ä¢ Augmented samples: ../data/augmented_sample/\")\n",
    "print(f\"   ‚Ä¢ Results and figures: ../results/\")\n",
    "\n",
    "print(f\"\\n‚úÖ MILESTONE 1 COMPLETION STATUS:\")\n",
    "print(f\"   ‚úì Data Collection: Complete\")\n",
    "print(f\"   ‚úì Data Exploration: Complete\")\n",
    "print(f\"   ‚úì Data Preprocessing: Complete\")\n",
    "print(f\"   ‚úì Data Augmentation: Complete\")\n",
    "\n",
    "print(f\"\\nüéØ NEXT STEPS (MILESTONE 2):\")\n",
    "print(f\"   ‚Ä¢ Implement U-Net model architecture\")\n",
    "print(f\"   ‚Ä¢ Set up training pipeline\")\n",
    "print(f\"   ‚Ä¢ Configure loss functions and metrics\")\n",
    "print(f\"   ‚Ä¢ Begin model training\")\n",
    "\n",
    "print(f\"\\nüéâ MILESTONE 1 SUCCESSFULLY COMPLETED!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create milestone completion file\n",
    "milestone_status = {\n",
    "    \"milestone_1\": {\n",
    "        \"status\": \"COMPLETED\",\n",
    "        \"completion_date\": pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"modules_completed\": [\n",
    "            \"Data Collection\",\n",
    "            \"Data Exploration (EDA)\",\n",
    "            \"Data Preprocessing\",\n",
    "            \"Data Augmentation\"\n",
    "        ],\n",
    "        \"deliverables\": {\n",
    "            \"processed_dataset\": f\"{processed_count} images\",\n",
    "            \"augmented_samples\": f\"{aug_stats['generated_augmentations']} samples\",\n",
    "            \"preprocessing_pipeline\": \"Implemented and tested\",\n",
    "            \"documentation\": \"Complete with statistics and visualizations\"\n",
    "        },\n",
    "        \"next_milestone\": \"Model Development and Training\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../results/data/milestone_1_completion.json', 'w') as f:\n",
    "    json.dump(milestone_status, f, indent=2)\n",
    "\n",
    "print(\"\\nMilestone completion status saved to ../results/data/milestone_1_completion.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
